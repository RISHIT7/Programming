{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto Diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.Variable(3.0)\n",
    "x = 1.0\n",
    "y = 1.0\n",
    "alpha = 0.01\n",
    "\n",
    "iterations = 30\n",
    "for iter in range(iterations):\n",
    "    # tensorflow's gradient tape to record the steps\n",
    "    with tf.GradientTape() as tape:\n",
    "        fwb = w*x\n",
    "        costJ = (fwb - y)**2\n",
    "\n",
    "    [dJdw] = tape.gradient(costJ, [w])\n",
    "\n",
    "    w.assign_add(-alpha*dJdw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "\n",
    "# iterations = 200\n",
    "# for iter in range(iterations):\n",
    "#     with tf.GradientTape() as tape:\n",
    "\n",
    "#         cost_val = cofiCostFuncV(X, W, b, Ynorm, R, num_users, num_movies, lambda)\n",
    "    \n",
    "#     grads  = tape.gradient(cost_value, [x, w, b])\n",
    "\n",
    "#     optimizer.apply_gradients(zip(grads, [x, w, b]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding related items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features $x^{(i)}$ of item $i$ are quite hard to interpret, but collectively they do convey something about that movie, i, and to find realted items, we find a movie with similar features calcualted as,\n",
    "$$||x^{(k)}-x^{(i)}||^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cold start problem\n",
    "- rank new items that few users have rated?\n",
    "- show something reasonable to new users who have rated few items?\n",
    "\n",
    "### Use side infromation about items or users:\n",
    "- Item: Genre, movie stars, studio,...\n",
    "- User: Demographics (age, gender, location), expressed preferences, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: cofi_cost_func\n",
    "# UNQ_C1\n",
    "\n",
    "def cofi_cost_func(X, W, b, Y, R, lambda_):\n",
    "    \"\"\"\n",
    "    Returns the cost for the content-based filtering\n",
    "    Args:\n",
    "      X (ndarray (num_movies,num_features)): matrix of item features\n",
    "      W (ndarray (num_users,num_features)) : matrix of user parameters\n",
    "      b (ndarray (1, num_users)            : vector of user parameters\n",
    "      Y (ndarray (num_movies,num_users)    : matrix of user ratings of movies\n",
    "      R (ndarray (num_movies,num_users)    : matrix, where R(i, j) = 1 if the i-th movies was rated by the j-th user\n",
    "      lambda_ (float): regularization parameter\n",
    "    Returns:\n",
    "      J (float) : Cost\n",
    "    \"\"\"\n",
    "    nm, nu = Y.shape\n",
    "    J = 0\n",
    "    ### START CODE HERE ###  \n",
    "    for i in range(nm):\n",
    "        for j in range(nu):\n",
    "            prediction = np.dot(X[i], W[j]) + b[:, j]\n",
    "            error = ((prediction-Y[i][j])**2)*R[i][j]\n",
    "            J += (1/2)*error\n",
    "    for i in range(nm):\n",
    "        J += lambda_*(np.sum(X[i]**2))/2\n",
    "    for j in range(nu):\n",
    "        J += lambda_*(np.sum(W[j]**2))/2\n",
    "    J = J[0]\n",
    "    ### END CODE HERE ### \n",
    "\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cofi_cost_func_v(X, W, b, Y, R, lambda_):\n",
    "    \"\"\"\n",
    "    Returns the cost for the content-based filtering\n",
    "    Vectorized for speed. Uses tensorflow operations to be compatible with custom training loop.\n",
    "    Args:\n",
    "      X (ndarray (num_movies,num_features)): matrix of item features\n",
    "      W (ndarray (num_users,num_features)) : matrix of user parameters\n",
    "      b (ndarray (1, num_users)            : vector of user parameters\n",
    "      Y (ndarray (num_movies,num_users)    : matrix of user ratings of movies\n",
    "      R (ndarray (num_movies,num_users)    : matrix, where R(i, j) = 1 if the i-th movies was rated by the j-th user\n",
    "      lambda_ (float): regularization parameter\n",
    "    Returns:\n",
    "      J (float) : Cost\n",
    "    \"\"\"\n",
    "    j = (tf.linalg.matmul(X, tf.transpose(W)) + b - Y)*R\n",
    "    J = 0.5 * tf.reduce_sum(j**2) + (lambda_/2) * (tf.reduce_sum(X**2) + tf.reduce_sum(W**2))\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
